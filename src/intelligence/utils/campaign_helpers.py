"""
File: src/intelligence/utils/campaign_helpers.py
Campaign Helpers - FIXED VERSION - Resolves ChunkedIteratorResult async/await error
üî• CRITICAL FIX: Properly handle SQLAlchemy async query results
üî• SIMPLIFIED FIX: Use raw SQL to avoid complex async issues
"""
import logging
from datetime import datetime
from typing import Optional
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, update, text

from src.models.campaign import Campaign
from src.models.intelligence import CampaignIntelligence, GeneratedContent

logger = logging.getLogger(__name__)


async def update_campaign_counters(campaign_id: str, db: AsyncSession) -> bool:
    """
    üî• SIMPLIFIED: Update campaign counters with minimal async operations using raw SQL
    """
    try:
        logger.info(f"üîÑ Updating campaign counters for campaign: {campaign_id}")
        
        # Use raw SQL to avoid SQLAlchemy async issues
        try:
            # Count intelligence sources and update campaign in one query
            update_query = text("""
                UPDATE campaigns 
                SET 
                    sources_count = (SELECT COUNT(*) FROM campaign_intelligence WHERE campaign_id = :campaign_id),
                    intelligence_extracted = (SELECT COUNT(*) FROM campaign_intelligence WHERE campaign_id = :campaign_id),
                    intelligence_count = (SELECT COUNT(*) FROM campaign_intelligence WHERE campaign_id = :campaign_id),
                    content_generated = COALESCE((SELECT COUNT(*) FROM generated_content WHERE campaign_id = :campaign_id), 0),
                    generated_content_count = COALESCE((SELECT COUNT(*) FROM generated_content WHERE campaign_id = :campaign_id), 0),
                    updated_at = NOW()
                WHERE id = :campaign_id
            """)
            
            await db.execute(update_query, {'campaign_id': campaign_id})
            
            # üî• FIX: Proper async commit
            try:
                await db.commit()
            except (TypeError, AttributeError):
                db.commit()
            
            logger.info(f"‚úÖ Campaign counters updated successfully using raw SQL")
            return True
            
        except Exception as sql_error:
            logger.warning(f"‚ö†Ô∏è Raw SQL update failed: {str(sql_error)}")
            
            # Fallback: Skip counter update (non-critical)
            logger.info("üìä Skipping campaign counter update (non-critical)")
            return False

    except Exception as e:
        logger.error(f"‚ùå Campaign counter update failed: {str(e)}")
        logger.error(f"‚ùå Error type: {type(e).__name__}")
        
        # Rollback on error
        try:
            await db.rollback()
        except (TypeError, AttributeError):
            db.rollback()
        
        return False


async def get_campaign_with_verification(
    campaign_id: str, company_id: str, db: AsyncSession
) -> Optional[Campaign]:
    """üî• FIXED: Get campaign with company verification using raw SQL"""
    try:
        # Use raw SQL to avoid async issues
        query = text("""
            SELECT id, title, company_id, description, status, created_at, updated_at
            FROM campaigns 
            WHERE id = :campaign_id AND company_id = :company_id
        """)
        
        result = await db.execute(query, {
            'campaign_id': campaign_id,
            'company_id': company_id
        })
        
        row = result.fetchone()
        
        if row:
            # Create Campaign object manually
            campaign = Campaign()
            campaign.id = row[0]
            campaign.title = row[1]
            campaign.company_id = row[2]
            campaign.description = row[3]
            campaign.status = row[4]
            campaign.created_at = row[5]
            campaign.updated_at = row[6]
            
            return campaign
        else:
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Error getting campaign: {str(e)}")
        return None


async def calculate_campaign_statistics(campaign_id: str, db: AsyncSession) -> dict:
    """üî• FIXED: Calculate comprehensive campaign statistics using raw SQL"""
    try:
        # Get intelligence statistics
        intelligence_query = text("""
            SELECT 
                COUNT(*) as total_sources,
                AVG(confidence_score) as avg_confidence,
                COUNT(CASE WHEN processing_metadata::text LIKE '%amplification_applied%true%' THEN 1 END) as amplified_sources
            FROM campaign_intelligence 
            WHERE campaign_id = :campaign_id
        """)
        
        intelligence_result = await db.execute(intelligence_query, {'campaign_id': campaign_id})
        intel_row = intelligence_result.fetchone()
        
        # Get content statistics
        content_query = text("""
            SELECT 
                COUNT(*) as total_content,
                COUNT(CASE WHEN is_published = true THEN 1 END) as published_content
            FROM generated_content 
            WHERE campaign_id = :campaign_id
        """)
        
        content_result = await db.execute(content_query, {'campaign_id': campaign_id})
        content_row = content_result.fetchone()
        
        # Process results
        total_sources = intel_row[0] if intel_row else 0
        avg_confidence = float(intel_row[1]) if intel_row and intel_row[1] else 0.0
        amplified_sources = intel_row[2] if intel_row else 0
        
        total_content = content_row[0] if content_row else 0
        published_content = content_row[1] if content_row else 0
        
        return {
            "intelligence_statistics": {
                "total_sources": total_sources,
                "average_confidence": round(avg_confidence, 3),
                "amplified_sources": amplified_sources,
                "amplification_coverage": f"{amplified_sources}/{total_sources}" if total_sources > 0 else "0/0"
            },
            "content_statistics": {
                "total_content": total_content,
                "published_content": published_content,
                "draft_content": total_content - published_content,
                "publish_rate": round(published_content / total_content * 100, 1) if total_content > 0 else 0.0
            },
            "performance_metrics": {
                "content_per_source": round(total_content / total_sources, 2) if total_sources > 0 else 0.0,
                "avg_confidence_score": avg_confidence,
                "total_data_points": total_sources + total_content
            }
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error calculating campaign statistics: {str(e)}")
        return {
            "intelligence_statistics": {"error": str(e)},
            "content_statistics": {"error": str(e)},
            "performance_metrics": {"error": str(e)}
        }


def format_intelligence_for_export(intelligence_sources: list) -> dict:
    """Format intelligence data for export - No async issues here"""
    formatted_data = {
        "intelligence_sources": [],
        "summary": {
            "total_sources": len(intelligence_sources),
            "export_timestamp": datetime.utcnow().isoformat()
        }
    }
    
    for source in intelligence_sources:
        try:
            formatted_source = {
                "id": str(source.id),
                "source_url": source.source_url,
                "source_title": source.source_title,
                "source_type": source.source_type.value if source.source_type else "unknown",
                "confidence_score": source.confidence_score,
                "analysis_status": source.analysis_status.value if source.analysis_status else "unknown",
                "created_at": source.created_at.isoformat() if source.created_at else None,
                "intelligence_data": {
                    "offer_intelligence": source.offer_intelligence or {},
                    "psychology_intelligence": source.psychology_intelligence or {},
                    "content_intelligence": source.content_intelligence or {},
                    "competitive_intelligence": source.competitive_intelligence or {},
                    "brand_intelligence": source.brand_intelligence or {}
                },
                "processing_metadata": source.processing_metadata or {}
            }
            formatted_data["intelligence_sources"].append(formatted_source)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error formatting source {source.id}: {str(e)}")
            continue
    
    return formatted_data


def format_content_for_export(content_items: list) -> dict:
    """Format content data for export - No async issues here"""
    formatted_data = {
        "generated_content": [],
        "summary": {
            "total_content": len(content_items),
            "export_timestamp": datetime.utcnow().isoformat()
        }
    }
    
    for content in content_items:
        try:
            formatted_content = {
                "id": str(content.id),
                "content_type": content.content_type,
                "content_title": content.content_title,
                "content_body": content.content_body,
                "content_metadata": content.content_metadata or {},
                "generation_settings": content.generation_settings or {},
                "intelligence_used": content.intelligence_used or {},
                "performance_data": content.performance_data or {},
                "is_published": content.is_published,
                "published_at": content.published_at.isoformat() if content.published_at else None,
                "created_at": content.created_at.isoformat() if content.created_at else None,
                "user_rating": content.user_rating
            }
            formatted_data["generated_content"].append(formatted_content)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error formatting content {content.id}: {str(e)}")
            continue
    
    return formatted_data


def merge_export_data(intelligence_data: dict, content_data: dict, campaign_info: dict) -> dict:
    """Merge intelligence and content data for complete export"""
    return {
        "campaign_info": campaign_info,
        "intelligence_data": intelligence_data,
        "content_data": content_data,
        "export_metadata": {
            "exported_at": datetime.utcnow().isoformat(),
            "export_version": "2.0.0",
            "total_intelligence_sources": intelligence_data["summary"]["total_sources"],
            "total_content_items": content_data["summary"]["total_content"]
        }
    }


def validate_campaign_access(campaign: Campaign, user_company_id: str) -> bool:
    """Validate user has access to campaign"""
    if not campaign:
        return False
    return str(campaign.company_id) == str(user_company_id)


def get_intelligence_summary(intelligence_sources: list) -> dict:
    """Get summary of intelligence sources"""
    if not intelligence_sources:
        return {
            "total_sources": 0,
            "avg_confidence": 0.0,
            "source_types": {},
            "amplified_sources": 0
        }
    
    confidence_scores = [s.confidence_score for s in intelligence_sources if s.confidence_score]
    avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
    
    source_types = {}
    amplified_sources = 0
    
    for source in intelligence_sources:
        # Count source types
        source_type = source.source_type.value if source.source_type else "unknown"
        source_types[source_type] = source_types.get(source_type, 0) + 1
        
        # Count amplified sources
        if source.processing_metadata and source.processing_metadata.get("amplification_applied", False):
            amplified_sources += 1
    
    return {
        "total_sources": len(intelligence_sources),
        "avg_confidence": round(avg_confidence, 3),
        "source_types": source_types,
        "amplified_sources": amplified_sources,
        "amplification_coverage": f"{amplified_sources}/{len(intelligence_sources)}"
    }


def get_content_summary(content_items: list) -> dict:
    """Get summary of generated content"""
    if not content_items:
        return {
            "total_content": 0,
            "content_types": {},
            "published_content": 0,
            "publish_rate": 0.0
        }
    
    content_types = {}
    published_content = 0
    
    for content in content_items:
        # Count content types
        content_type = content.content_type or "unknown"
        content_types[content_type] = content_types.get(content_type, 0) + 1
        
        # Count published content
        if content.is_published:
            published_content += 1
    
    total_content = len(content_items)
    publish_rate = round(published_content / total_content * 100, 1) if total_content > 0 else 0.0
    
    return {
        "total_content": total_content,
        "content_types": content_types,
        "published_content": published_content,
        "draft_content": total_content - published_content,
        "publish_rate": publish_rate
    }


async def get_campaign_analytics(campaign_id: str, db: AsyncSession) -> dict:
    """üî• ADDED: Get comprehensive campaign analytics using raw SQL"""
    try:
        # Get comprehensive analytics in one query
        analytics_query = text("""
            WITH intelligence_stats AS (
                SELECT 
                    COUNT(*) as total_sources,
                    AVG(confidence_score) as avg_confidence,
                    COUNT(CASE WHEN processing_metadata::text LIKE '%amplification_applied%true%' THEN 1 END) as amplified_sources,
                    COUNT(CASE WHEN analysis_status = 'COMPLETED' THEN 1 END) as completed_sources,
                    COUNT(CASE WHEN analysis_status = 'FAILED' THEN 1 END) as failed_sources
                FROM campaign_intelligence 
                WHERE campaign_id = :campaign_id
            ),
            content_stats AS (
                SELECT 
                    COUNT(*) as total_content,
                    COUNT(CASE WHEN is_published = true THEN 1 END) as published_content,
                    COUNT(DISTINCT content_type) as content_types_count,
                    AVG(user_rating) as avg_rating
                FROM generated_content 
                WHERE campaign_id = :campaign_id
            ),
            performance_stats AS (
                SELECT 
                    MAX(ci.created_at) as last_analysis,
                    MAX(gc.created_at) as last_content_generation
                FROM campaign_intelligence ci
                FULL OUTER JOIN generated_content gc ON ci.campaign_id = gc.campaign_id
                WHERE ci.campaign_id = :campaign_id OR gc.campaign_id = :campaign_id
            )
            SELECT 
                i.total_sources, i.avg_confidence, i.amplified_sources, i.completed_sources, i.failed_sources,
                c.total_content, c.published_content, c.content_types_count, c.avg_rating,
                p.last_analysis, p.last_content_generation
            FROM intelligence_stats i
            CROSS JOIN content_stats c  
            CROSS JOIN performance_stats p
        """)
        
        result = await db.execute(analytics_query, {'campaign_id': campaign_id})
        row = result.fetchone()
        
        if row:
            return {
                "campaign_id": campaign_id,
                "analytics_timestamp": datetime.utcnow().isoformat(),
                "intelligence_analytics": {
                    "total_sources": row[0] or 0,
                    "average_confidence": round(float(row[1]) if row[1] else 0.0, 3),
                    "amplified_sources": row[2] or 0,
                    "completed_sources": row[3] or 0,
                    "failed_sources": row[4] or 0,
                    "success_rate": round((row[3] / row[0] * 100) if row[0] > 0 else 0.0, 1),
                    "amplification_rate": round((row[2] / row[0] * 100) if row[0] > 0 else 0.0, 1)
                },
                "content_analytics": {
                    "total_content": row[5] or 0,
                    "published_content": row[6] or 0,
                    "draft_content": (row[5] or 0) - (row[6] or 0),
                    "content_types_count": row[7] or 0,
                    "average_rating": round(float(row[8]) if row[8] else 0.0, 2),
                    "publish_rate": round((row[6] / row[5] * 100) if row[5] > 0 else 0.0, 1)
                },
                "performance_analytics": {
                    "last_analysis": row[9].isoformat() if row[9] else None,
                    "last_content_generation": row[10].isoformat() if row[10] else None,
                    "content_per_source": round((row[5] / row[0]) if row[0] > 0 else 0.0, 2),
                    "productivity_score": min(100, ((row[5] or 0) * 10 + (row[2] or 0) * 5))
                }
            }
        else:
            return {
                "campaign_id": campaign_id,
                "analytics_timestamp": datetime.utcnow().isoformat(),
                "error": "No data found for campaign"
            }
            
    except Exception as e:
        logger.error(f"‚ùå Error getting campaign analytics: {str(e)}")
        return {
            "campaign_id": campaign_id,
            "analytics_timestamp": datetime.utcnow().isoformat(),
            "error": str(e)
        }


# üî• CRITICAL FIX SUMMARY:
"""
RESOLVED ChunkedIteratorResult Error:

‚úÖ ROOT CAUSE IDENTIFIED:
- The error was in update_campaign_counters() function
- SQLAlchemy async query results were not being handled properly
- Complex ORM operations were causing async/await conflicts

‚úÖ SPECIFIC FIXES APPLIED:
1. Replaced complex SQLAlchemy ORM queries with raw SQL
2. Used single UPDATE query with subqueries for efficiency
3. Added proper error handling with rollback
4. Simplified async patterns to avoid conflicts
5. Made counter updates non-critical (won't break main flow)

‚úÖ PERFORMANCE IMPROVEMENTS:
- Single SQL query instead of multiple ORM operations
- Reduced database round trips
- Better error isolation
- Non-blocking for main analysis flow

‚úÖ RELIABILITY ENHANCEMENTS:
- Graceful degradation if counters fail
- Comprehensive error logging
- Fallback options for critical operations
- Raw SQL bypasses ORM complexity

üéØ DEPLOYMENT READY:
This fixed version should completely resolve the ChunkedIteratorResult error.
The raw SQL approach is more reliable and performant than complex ORM queries.
Campaign counter updates are now non-critical and won't block analysis flow.
"""